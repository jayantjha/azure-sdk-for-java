// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.openai.implementation;

import com.azure.ai.openai.AzureOpenAIServiceVersion;
import com.azure.core.annotation.BodyParam;
import com.azure.core.annotation.ExpectedResponses;
import com.azure.core.annotation.HeaderParam;
import com.azure.core.annotation.Host;
import com.azure.core.annotation.HostParam;
import com.azure.core.annotation.Post;
import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceInterface;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.annotation.UnexpectedResponseExceptionType;
import com.azure.core.exception.ClientAuthenticationException;
import com.azure.core.exception.HttpResponseException;
import com.azure.core.exception.ResourceModifiedException;
import com.azure.core.exception.ResourceNotFoundException;
import com.azure.core.http.rest.RequestOptions;
import com.azure.core.http.rest.Response;
import com.azure.core.http.rest.RestProxy;
import com.azure.core.util.BinaryData;
import com.azure.core.util.Context;
import com.azure.core.util.FluxUtil;
import reactor.core.publisher.Mono;

/**
 * An instance of this class provides access to all the operations defined in AzureChats.
 */
public final class AzureChatsImpl {
    /**
     * The proxy service used to perform REST calls.
     */
    private final AzureChatsService service;

    /**
     * The service client containing this operation class.
     */
    private final AzureOpenAIClientImpl client;

    /**
     * Initializes an instance of AzureChatsImpl.
     * 
     * @param client the instance of the service client containing this operation class.
     */
    AzureChatsImpl(AzureOpenAIClientImpl client) {
        this.service
            = RestProxy.create(AzureChatsService.class, client.getHttpPipeline(), client.getSerializerAdapter());
        this.client = client;
    }

    /**
     * Gets Service version.
     * 
     * @return the serviceVersion value.
     */
    public AzureOpenAIServiceVersion getServiceVersion() {
        return client.getServiceVersion();
    }

    /**
     * The interface defining all the services for AzureOpenAIClientAzureChats to be used by the proxy service to
     * perform REST calls.
     */
    @Host("{endpoint}/openai")
    @ServiceInterface(name = "AzureOpenAIClientAzu")
    public interface AzureChatsService {
        @Post("/chat/completions")
        @ExpectedResponses({ 200 })
        @UnexpectedResponseExceptionType(value = ClientAuthenticationException.class, code = { 401 })
        @UnexpectedResponseExceptionType(value = ResourceNotFoundException.class, code = { 404 })
        @UnexpectedResponseExceptionType(value = ResourceModifiedException.class, code = { 409 })
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Mono<Response<BinaryData>> createChatCompletion(@HostParam("endpoint") String endpoint,
            @HeaderParam("accept") String accept, @BodyParam("application/json") BinaryData createChatCompletionRequest,
            RequestOptions requestOptions, Context context);

        @Post("/chat/completions")
        @ExpectedResponses({ 200 })
        @UnexpectedResponseExceptionType(value = ClientAuthenticationException.class, code = { 401 })
        @UnexpectedResponseExceptionType(value = ResourceNotFoundException.class, code = { 404 })
        @UnexpectedResponseExceptionType(value = ResourceModifiedException.class, code = { 409 })
        @UnexpectedResponseExceptionType(HttpResponseException.class)
        Response<BinaryData> createChatCompletionSync(@HostParam("endpoint") String endpoint,
            @HeaderParam("accept") String accept, @BodyParam("application/json") BinaryData createChatCompletionRequest,
            RequestOptions requestOptions, Context context);
    }

    /**
     * The createChatCompletion operation.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     data_sources (Optional): [
     *          (Optional){
     *             type: String (Required)
     *         }
     *     ]
     *     messages (Required): [
     *          (Required){
     *             role: String (Required)
     *         }
     *     ]
     *     model: String(o1-preview/o1-preview-2024-09-12/o1-mini/o1-mini-2024-09-12/gpt-4o/gpt-4o-2024-08-06/gpt-4o-2024-05-13/chatgpt-4o-latest/gpt-4o-mini/gpt-4o-mini-2024-07-18/gpt-4-turbo/gpt-4-turbo-2024-04-09/gpt-4-0125-preview/gpt-4-turbo-preview/gpt-4-1106-preview/gpt-4-vision-preview/gpt-4/gpt-4-0314/gpt-4-0613/gpt-4-32k/gpt-4-32k-0314/gpt-4-32k-0613/gpt-3.5-turbo/gpt-3.5-turbo-16k/gpt-3.5-turbo-0301/gpt-3.5-turbo-0613/gpt-3.5-turbo-1106/gpt-3.5-turbo-0125/gpt-3.5-turbo-16k-0613) (Required)
     *     frequency_penalty: Double (Optional)
     *     logit_bias (Optional): {
     *         String: int (Required)
     *     }
     *     logprobs: Boolean (Optional)
     *     top_logprobs: Integer (Optional)
     *     max_tokens: Integer (Optional)
     *     max_completion_tokens: Integer (Optional)
     *     n: Integer (Optional)
     *     presence_penalty: Double (Optional)
     *     response_format (Optional): {
     *         type: String (Required)
     *     }
     *     seed: Long (Optional)
     *     service_tier: String(auto/default) (Optional)
     *     stop: BinaryData (Optional)
     *     stream: Boolean (Optional)
     *     stream_options (Optional): {
     *         include_usage: Boolean (Optional)
     *     }
     *     temperature: Double (Optional)
     *     top_p: Double (Optional)
     *     tools (Optional): [
     *          (Optional){
     *             type: String (Required)
     *             function (Required): {
     *                 description: String (Optional)
     *                 name: String (Required)
     *                 parameters (Optional): {
     *                      (Optional): {
     *                         String: Object (Required)
     *                     }
     *                 }
     *                 strict: Boolean (Optional)
     *             }
     *         }
     *     ]
     *     tool_choice: BinaryData (Optional)
     *     parallel_tool_calls: Boolean (Optional)
     *     user: String (Optional)
     *     function_call: BinaryData (Optional)
     *     functions (Optional): [
     *          (Optional){
     *             description: String (Optional)
     *             name: String (Required)
     *             parameters (Optional): (recursive schema, see parameters above)
     *         }
     *     ]
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     id: String (Required)
     *     choices (Required): [
     *          (Required){
     *             finish_reason: String(stop/length/tool_calls/content_filter/function_call) (Required)
     *             index: int (Required)
     *             message (Required): {
     *                 content: String (Required)
     *                 refusal: String (Required)
     *                 tool_calls (Optional): [
     *                      (Optional){
     *                         id: String (Required)
     *                         type: String (Required)
     *                         function (Required): {
     *                             name: String (Required)
     *                             arguments: String (Required)
     *                         }
     *                     }
     *                 ]
     *                 role: String (Required)
     *                 function_call (Optional): {
     *                     name: String (Required)
     *                     arguments: String (Required)
     *                 }
     *             }
     *             logprobs (Required): {
     *                 content (Required): [
     *                      (Required){
     *                         token: String (Required)
     *                         logprob: double (Required)
     *                         bytes (Required): [
     *                             int (Required)
     *                         ]
     *                         top_logprobs (Required): [
     *                              (Required){
     *                                 token: String (Required)
     *                                 logprob: double (Required)
     *                                 bytes (Required): [
     *                                     int (Required)
     *                                 ]
     *                             }
     *                         ]
     *                     }
     *                 ]
     *                 refusal (Required): [
     *                     (recursive schema, see above)
     *                 ]
     *             }
     *         }
     *     ]
     *     created: long (Required)
     *     model: String (Required)
     *     service_tier: String(scale/default) (Optional)
     *     system_fingerprint: String (Optional)
     *     object: String (Required)
     *     usage (Optional): {
     *         completion_tokens: int (Required)
     *         prompt_tokens: int (Required)
     *         total_tokens: int (Required)
     *         completion_tokens_details (Optional): {
     *             reasoning_tokens: Integer (Optional)
     *         }
     *     }
     *     prompt_filter_results (Optional): [
     *          (Optional){
     *             prompt_index: int (Required)
     *             content_filter_results (Required): {
     *                 prompt_index: Integer (Optional)
     *                 content_filter_results (Optional): {
     *                     sexual (Optional): {
     *                         filtered: boolean (Required)
     *                         severity: String(safe/low/medium/high) (Required)
     *                     }
     *                     hate (Optional): (recursive schema, see hate above)
     *                     violence (Optional): (recursive schema, see violence above)
     *                     self_harm (Optional): (recursive schema, see self_harm above)
     *                     profanity (Optional): {
     *                         filtered: boolean (Required)
     *                         detected: boolean (Required)
     *                     }
     *                     custom_blocklists (Optional): {
     *                         filtered: boolean (Required)
     *                         details (Optional): [
     *                              (Optional){
     *                                 filtered: boolean (Required)
     *                                 id: String (Required)
     *                             }
     *                         ]
     *                     }
     *                     error (Optional): {
     *                         code: int (Required)
     *                         message: String (Required)
     *                     }
     *                     jailbreak (Required): (recursive schema, see jailbreak above)
     *                     indirect_attack (Required): (recursive schema, see indirect_attack above)
     *                 }
     *             }
     *         }
     *     ]
     * }
     * }</pre>
     * 
     * @param createChatCompletionRequest The createChatCompletionRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the extended top-level chat completion response model for the Azure OpenAI service.
     * This model adds Responsible AI content filter annotations for prompt input along with {@link Response} on
     * successful completion of {@link Mono}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Mono<Response<BinaryData>> createChatCompletionWithResponseAsync(BinaryData createChatCompletionRequest,
        RequestOptions requestOptions) {
        final String accept = "application/json";
        return FluxUtil.withContext(context -> service.createChatCompletion(this.client.getEndpoint(), accept,
            createChatCompletionRequest, requestOptions, context));
    }

    /**
     * The createChatCompletion operation.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     data_sources (Optional): [
     *          (Optional){
     *             type: String (Required)
     *         }
     *     ]
     *     messages (Required): [
     *          (Required){
     *             role: String (Required)
     *         }
     *     ]
     *     model: String(o1-preview/o1-preview-2024-09-12/o1-mini/o1-mini-2024-09-12/gpt-4o/gpt-4o-2024-08-06/gpt-4o-2024-05-13/chatgpt-4o-latest/gpt-4o-mini/gpt-4o-mini-2024-07-18/gpt-4-turbo/gpt-4-turbo-2024-04-09/gpt-4-0125-preview/gpt-4-turbo-preview/gpt-4-1106-preview/gpt-4-vision-preview/gpt-4/gpt-4-0314/gpt-4-0613/gpt-4-32k/gpt-4-32k-0314/gpt-4-32k-0613/gpt-3.5-turbo/gpt-3.5-turbo-16k/gpt-3.5-turbo-0301/gpt-3.5-turbo-0613/gpt-3.5-turbo-1106/gpt-3.5-turbo-0125/gpt-3.5-turbo-16k-0613) (Required)
     *     frequency_penalty: Double (Optional)
     *     logit_bias (Optional): {
     *         String: int (Required)
     *     }
     *     logprobs: Boolean (Optional)
     *     top_logprobs: Integer (Optional)
     *     max_tokens: Integer (Optional)
     *     max_completion_tokens: Integer (Optional)
     *     n: Integer (Optional)
     *     presence_penalty: Double (Optional)
     *     response_format (Optional): {
     *         type: String (Required)
     *     }
     *     seed: Long (Optional)
     *     service_tier: String(auto/default) (Optional)
     *     stop: BinaryData (Optional)
     *     stream: Boolean (Optional)
     *     stream_options (Optional): {
     *         include_usage: Boolean (Optional)
     *     }
     *     temperature: Double (Optional)
     *     top_p: Double (Optional)
     *     tools (Optional): [
     *          (Optional){
     *             type: String (Required)
     *             function (Required): {
     *                 description: String (Optional)
     *                 name: String (Required)
     *                 parameters (Optional): {
     *                      (Optional): {
     *                         String: Object (Required)
     *                     }
     *                 }
     *                 strict: Boolean (Optional)
     *             }
     *         }
     *     ]
     *     tool_choice: BinaryData (Optional)
     *     parallel_tool_calls: Boolean (Optional)
     *     user: String (Optional)
     *     function_call: BinaryData (Optional)
     *     functions (Optional): [
     *          (Optional){
     *             description: String (Optional)
     *             name: String (Required)
     *             parameters (Optional): (recursive schema, see parameters above)
     *         }
     *     ]
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     id: String (Required)
     *     choices (Required): [
     *          (Required){
     *             finish_reason: String(stop/length/tool_calls/content_filter/function_call) (Required)
     *             index: int (Required)
     *             message (Required): {
     *                 content: String (Required)
     *                 refusal: String (Required)
     *                 tool_calls (Optional): [
     *                      (Optional){
     *                         id: String (Required)
     *                         type: String (Required)
     *                         function (Required): {
     *                             name: String (Required)
     *                             arguments: String (Required)
     *                         }
     *                     }
     *                 ]
     *                 role: String (Required)
     *                 function_call (Optional): {
     *                     name: String (Required)
     *                     arguments: String (Required)
     *                 }
     *             }
     *             logprobs (Required): {
     *                 content (Required): [
     *                      (Required){
     *                         token: String (Required)
     *                         logprob: double (Required)
     *                         bytes (Required): [
     *                             int (Required)
     *                         ]
     *                         top_logprobs (Required): [
     *                              (Required){
     *                                 token: String (Required)
     *                                 logprob: double (Required)
     *                                 bytes (Required): [
     *                                     int (Required)
     *                                 ]
     *                             }
     *                         ]
     *                     }
     *                 ]
     *                 refusal (Required): [
     *                     (recursive schema, see above)
     *                 ]
     *             }
     *         }
     *     ]
     *     created: long (Required)
     *     model: String (Required)
     *     service_tier: String(scale/default) (Optional)
     *     system_fingerprint: String (Optional)
     *     object: String (Required)
     *     usage (Optional): {
     *         completion_tokens: int (Required)
     *         prompt_tokens: int (Required)
     *         total_tokens: int (Required)
     *         completion_tokens_details (Optional): {
     *             reasoning_tokens: Integer (Optional)
     *         }
     *     }
     *     prompt_filter_results (Optional): [
     *          (Optional){
     *             prompt_index: int (Required)
     *             content_filter_results (Required): {
     *                 prompt_index: Integer (Optional)
     *                 content_filter_results (Optional): {
     *                     sexual (Optional): {
     *                         filtered: boolean (Required)
     *                         severity: String(safe/low/medium/high) (Required)
     *                     }
     *                     hate (Optional): (recursive schema, see hate above)
     *                     violence (Optional): (recursive schema, see violence above)
     *                     self_harm (Optional): (recursive schema, see self_harm above)
     *                     profanity (Optional): {
     *                         filtered: boolean (Required)
     *                         detected: boolean (Required)
     *                     }
     *                     custom_blocklists (Optional): {
     *                         filtered: boolean (Required)
     *                         details (Optional): [
     *                              (Optional){
     *                                 filtered: boolean (Required)
     *                                 id: String (Required)
     *                             }
     *                         ]
     *                     }
     *                     error (Optional): {
     *                         code: int (Required)
     *                         message: String (Required)
     *                     }
     *                     jailbreak (Required): (recursive schema, see jailbreak above)
     *                     indirect_attack (Required): (recursive schema, see indirect_attack above)
     *                 }
     *             }
     *         }
     *     ]
     * }
     * }</pre>
     * 
     * @param createChatCompletionRequest The createChatCompletionRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the extended top-level chat completion response model for the Azure OpenAI service.
     * This model adds Responsible AI content filter annotations for prompt input along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> createChatCompletionWithResponse(BinaryData createChatCompletionRequest,
        RequestOptions requestOptions) {
        final String accept = "application/json";
        return service.createChatCompletionSync(this.client.getEndpoint(), accept, createChatCompletionRequest,
            requestOptions, Context.NONE);
    }
}
